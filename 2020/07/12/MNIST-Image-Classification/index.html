<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning," />










<meta name="description" content="Abstract  In this project, given MNIST dataset, we modeled it as a multiclass classification problem where we implemented different classification algorithms. In addition, we also conducted feature vi">
<meta property="og:type" content="article">
<meta property="og:title" content="MNIST Image Classification">
<meta property="og:url" content="http://yoursite.com/2020/07/12/MNIST-Image-Classification/index.html">
<meta property="og:site_name" content="Yifan Cheng Personal Blog">
<meta property="og:description" content="Abstract  In this project, given MNIST dataset, we modeled it as a multiclass classification problem where we implemented different classification algorithms. In addition, we also conducted feature vi">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/raw_MNIST.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/Random_images.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/log_reg.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/cross_entropy.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/softmax_result.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/RSS.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/ridge.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/ridge_result.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/lasso.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/lasso_result.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/2_layer.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN_param.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN_compare.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN_result.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/CNN_architecture.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_architecture.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_ar_box.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/SGD_accuracy.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_opt.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_opt_box.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/opt_accuracy.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/svm_result.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/conf_matrix_SVM.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_model.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/dim_PCA.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/PCA.png">
<meta property="og:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/t-SNE.png">
<meta property="article:published_time" content="2020-07-12T19:09:00.000Z">
<meta property="article:modified_time" content="2020-07-12T23:18:15.745Z">
<meta property="article:author" content="Yifan Cheng">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/raw_MNIST.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/07/12/MNIST-Image-Classification/"/>





  <title>MNIST Image Classification | Yifan Cheng Personal Blog</title>
  








<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yifan Cheng Personal Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/12/MNIST-Image-Classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yifan Cheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/charlotte.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yifan Cheng Personal Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MNIST Image Classification</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-12T12:09:00-07:00">
                2020-07-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3>Abstract</h3>

<p>In this project, given MNIST dataset, we modeled it as a multiclass classification problem where we implemented different classification algorithms. In addition, we also conducted feature visualization and network diagnosis using PCA and t-SNE. Six different models including Logistic Regression (Softmax), Logistic Regression with Ridge loss, Logistic Regression with Lasso loss, simple-NN, CNN and SVM were studied and their performances were measured and compared. Among which, CNN performed the best. </p>
<h3>I. Data</h3>

<h4>1.1 Dataset Introduction</h4>

<p>MNIST dataset is a handwritten digits dataset which has a training set of 60,000 examples and a test set of 10,000 examples. It’s a subset of a larger set available from NIST. In the dataset, the digits have been size-normalized and centered in a fixed-size image (28x28 pixel box) by computing the center of mass of the pixels. </p>
<h4>1.2 Data Preprocessing</h4>

<p>MNIST data is stored in a simple file format designed for storing vectors and multidimensional</p>
<p>matrices. However, when we implement classification methods, typically the numpy array is the</p>
<p>easiest way for follow-up model construction, thus, we need to read in 4 files: <code>train-images- idx3-ubyte</code>, <code>train-labels-idx1-ubyte</code>, <code>t10k-images-idx3-ubyte</code>, <code>t10k-labels-idx1-ubyte</code>and transform them into operable format.</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/raw_MNIST.png" alt="raw_MNIST" style="zoom:50%;" /></p>
<p align="center"><font size=2>Fig 1. Overview of raw MNIST dataset</font></p>

<p>From Fig.1, we can see that in the image files, pixels are organized row-wise. Values range from 0 to 255, where 0 means background (white), 255 means foreground (black). In the label files, the labels values are 0 to 9. </p>
<p>In <code>util.py</code>, we defined read_image_labels and load_dataset function to load data from idx3-ubyte and idx1-ubyte file. Fig.2 shows some random training and test images retrieved from raw dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_images_labels</span><span class="params">(images_path, labels_path)</span>:</span></span><br><span class="line">    <span class="comment"># read images</span></span><br><span class="line">    <span class="comment"># rb: read binary mode</span></span><br><span class="line">    <span class="keyword">with</span> open(images_path, <span class="string">'rb'</span>) <span class="keyword">as</span> file:</span><br><span class="line">        <span class="comment"># deal with header: 32 bit integer in the first 4 rows</span></span><br><span class="line">        magic_number, num_images, num_rows, num_cols = struct.unpack(<span class="string">'&gt;IIII'</span>, file.read(<span class="number">16</span>))</span><br><span class="line">        <span class="comment"># B: unsigned char</span></span><br><span class="line">        fmt_image = array(<span class="string">'B'</span>, file.read())</span><br><span class="line">        images = np.empty((num_images, num_rows, num_cols))</span><br><span class="line">        <span class="comment"># read one image at a time sequentially</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_images):</span><br><span class="line">            images[i] = np.array(fmt_image[i * num_rows * num_cols : (i+<span class="number">1</span>) * num_rows * num_cols]).reshape(num_rows, num_cols)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read labels</span></span><br><span class="line">    <span class="keyword">with</span> open(labels_path, <span class="string">'rb'</span>) <span class="keyword">as</span> file:</span><br><span class="line">        <span class="comment"># deal with header: 32 bit integer in the first 2 rows</span></span><br><span class="line">        magic_number, num_items = struct.unpack(<span class="string">"&gt;II"</span>, file.read(<span class="number">8</span>))</span><br><span class="line">        <span class="comment"># B: unsigned char</span></span><br><span class="line">        labels = array(<span class="string">'B'</span>, file.read()).tolist()</span><br><span class="line">        labels = np.asarray(labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/Random_images.png" alt="Random_images" style="zoom:50%;" /></p>
<p align="center"><font size=2>Fig 2. Random training and test images</font></p>



<h3>II. Image Classification</h3>

<p>In this part, we implemented 6 different image classification methods: Logistic Regression (Softmax), Logistic Regression with Ridge loss, Logistic Regression with Lasso loss, simple-NN, CNN and SVM. </p>
<h4>2.1 Logistic Regression</h4>

<h5>2.1.1 Multinomial Logistic Regression</h5>

<p>Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. It allows us to handle $y(i) \in \{1, …,k\}$where <em>K</em>  is the number of classes. In the model, we assume that the conditional distribution of <em>y</em> given <em>x</em>  is given by </p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/log_reg.png" alt="log_reg" style="zoom:70%;" /></p>
<p>In <code>Logreg.py</code>, we built the softmax regression model from scratch without using any built-in package other than numpy and matplotlib. In this part and following two sections involving regularization, due to the long training time using complete dataset, we randomly sample <em>10k</em>  examples from the <em>60k</em>  training samples. For the first <em>2k</em> rows, we used them as validation set. The rest <em>8k</em> rows are used as training set. The key points in building softmax regression model is to derive the cross-entropy loss function which is given by</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/cross_entropy.png" alt="cross_entropy" style="zoom:70%;" /></p>
<p>Thus, we wrote <code>one_hot_labels</code> and <code>softmax</code> function to assist in deriving the loss function of softmax regression. By setting the learning rate $\alpha=0.01$ threshold for determining convergene $eps=1e-4$, we iterated to minimize the loss function using SGD. Finally, we can get the model accuracy of 0.8905.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot_labels</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    m = x.shape[<span class="number">0</span>]</span><br><span class="line">    one_hot_labels = np.zeros((m, K))</span><br><span class="line">    one_hot_labels[np.arange(m), y] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> one_hot_labels</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    x = x.astype(np.float128)</span><br><span class="line">    z = np.max(x)</span><br><span class="line">    softmax = np.exp(x-z) / np.sum(np.exp(x-z), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> softmax</span><br></pre></td></tr></table></figure>
<p align="center"><font size=2>Table 1. Performance of Softmax Regression</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/softmax_result.png" alt="softmax_result" style="zoom:40%;" /></p>
<h5> 2.1.2 Multinomial Logistic Regression with Ridge Loss</h5>

<p>Recall that the OLS estimates $\alpha=0.01$ by minimizing </p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/RSS.png" alt="RSS" style="zoom:80%;" /></p>
<p>Similar to OLS, Ridge regression estimates $\beta_0,\beta_1…$ by minimizing</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/ridge.png" alt="ridge" style="zoom:70%;" /></p>
<p>The major difference lies in the regularization term, $\lambda \sum_j \beta_j^2$, is called a shrinkage penalty, which is small when $\beta_0,\beta_1…$ are close to zero. The tuning parameter $\lambda$ serves to control the relative impact of these two terms on the regression coefficient estimates. Here we set $\lambda=1e-4$. With Ridge loss, we improve the model accuracy from 0.8905 to 0.8914.</p>
<p align="center"><font size=2>Table 2. Performance of Softmax Regression with Ridge loss</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/ridge_result.png" alt="ridge_result" style="zoom:40%;" /></p>
<h5>2.1.3 Multinomial Logistic Regression with Lasso Loss</h5>

<p>Similar as Ridge regression, the Lasso regression also adds a penalty term which uses L1 norm instead of L2 norm. Here we also set $\lambda=1e-4$ . With Ridge loss, we improve the model accuracy from 0.8905 to 0.8918.</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/lasso.png" alt="lasso" style="zoom:70%;" /></p>
<p align="center"><font size=2>Table 3. Performance of Softmax Regression with Lasso loss</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/lasso_result.png" alt="lasso_result" style="zoom:40%;" /></p>
<h5>2.1.4 Basic Conclusion for Logistic Regression</h5>

<p>According to results we got in section 2.1.1 – 2.1.3, we can see that with regularization, the test accuracy is improved to some degree. The Ridge and Lasso regularization are functioned as increasing the bias if our model overfits and suffers from high variance. Nevertheless, to much bias can lead to underfitting.</p>
<h4>2.2 Neural Network</h4>

<h5>2.2.1 Simple-NN</h5>

<p>As we mentioned before, in previous three sections about logistic regression with/without regularization, we used a subset data of <em>10k</em> size. Beginning from this part, we used the complete MNIST dataset of <em>60K</em> size. For the first <em>10k</em> rows, we used them as validation set. The rest <em>50k</em> rows are used as training set.</p>
<p>In this part, we built a simple 2-layer neural network with one hidden layer and one output layer from scratch. From the input layer to hidden layer, sigmoid function is used as activation function. From the hidden layer to output layer, softmax function is used as activation function, which can be expressed as </p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN.png" alt="simple_NN" style="zoom:40%;" /></p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/2_layer.png" alt="2_layer" style="zoom:40%;" /></p>
<p align="center"><font size=2>Fig 3. Performance of Softmax Regression with Lasso loss</font></p>

<p>The basic idea of constructing neural network consists of two elements: forward propagation and backward propagation. In forward propagation, the input data is fed in the forward direction through the network. Each hidden layer accepts the input data, processes it as per the activation function and passes to the successive layer. In backward propagation, we allow the information to go back from the cost backward through the network in order to compute the gradient and update the parameters in the neural network. </p>
<p>In <code>nn.py</code>, we implemented this neural network by minimizing the cross-entropy loss using mini-batch gradient descent. Below are some of the training parameters.</p>
<p align="center"><font size=2>Table 4. Training parameters of simple-NN</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN_param.png" alt="simple_NN_param" style="zoom:35%;" /></p>
<p>In addition to the baseline model, we added a regularization term to the cross-entropy loss to get the regularized model. Fig 4 shows the loss vs epoch and accuracy vs epoch in baseline and regularized model.</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN_compare.png" alt="simple_NN_compare"></p>
<p align="center"><font size=2>Fig 4. Loss vs epoch, Accuracy vs epoch</font></p>

<p align="center"><font size=2>Table 5. Comparison of baseline and regularized model</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/simple_NN_result.png" alt="simple_NN_result" style="zoom:35%;" /></p>
<p>Apparently from table 5, the regularized model improved the model accuracy from 0.9310 to 0.9493. We can interpret the better performance by looking at fig 4. Without regularization, the overfitting is apparent as there is big difference between the performances on the the training and validation data in terms of both cross-entropy loss and accuracy. In contrast, with regularization, the performance on validation data follows that on training data closely, does much better than without regularization. </p>
<h5> 2.2.2 CNN</h5>

<h6>1. Build Model</h6>

<p><strong>1) Different Model Architecture</strong></p>
<p>In this part, we used <code>keras</code> package in <code>tensorflow</code> to build two CNN models. These two model network architectures are generated by <code>keras</code> as fig 5 shows.</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/CNN_architecture.png" alt="CNN_architecture" style="zoom:40%;" /></p>
<p align="center"><font size=2>Fig 5. CNN model-1 and model-2 architecture</font></p>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    <span class="comment"># model 1</span></span><br><span class="line">    model.add(Conv2D(<span class="number">64</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">'relu'</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">    model.add(Conv2D(<span class="number">32</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line">    opt = SGD(lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">    model.compile(optimizer=opt, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">    <span class="comment"># model 2</span></span><br><span class="line">    <span class="comment"># model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))</span></span><br><span class="line">    <span class="comment"># model.add(MaxPooling2D((2, 2)))</span></span><br><span class="line">    <span class="comment"># model.add(Flatten())</span></span><br><span class="line">    <span class="comment"># model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))</span></span><br><span class="line">    <span class="comment"># model.add(Dense(10, activation='softmax'))</span></span><br><span class="line">    <span class="comment"># opt = SGD(lr=0.01, momentum=0.9)</span></span><br><span class="line">    <span class="comment"># model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>For the first model, we used Conv2D as the first two layers to deal with our input images which are seen as 2-dimensional matrices. We designed the number of nodes in each layer to be 64 in the first one and 32 in the second one. In the meantime, the kernel size 3 represents for the 3x3 filter matrix. And we used ReLU as the activation function for these two layers. A flatten layer used to reshape and build connection between convolution and dense layer is implemented before the output layer, which is a dense layer with 10 nodes using softmax as activation function.</p>
<p>Similar as the first one, the second CNN model is just a little more complicated because we added more layers and tuned some of the parameters to see the effect. For the first two layers, we still used Conv2D but we changed the nodes in the second layer from 32 to 64. Also, before the flatten layer, we added a MaxPooling2D layer to down sample the input. Before the final dense layer same as model 1, we added another 100-node dense layer to interpret the features.</p>
<p>In this part, we used the SGD with a learning rate of 0.01 and a momentum of 0.9 as the optimizer for both model 1 and 2.</p>
<p><strong>2) Different Optimizer</strong></p>
<p>In the training process of CNN model 2, we also changed the optimizer from SGD to Adam to see if the optimizer has an impact on the result and model performance.</p>
<h6>2. Evaluate Model</h6>

<p>After model construction, we used 5-Fold cross validation method to split training and validation set (K=5). First we split dataset into 5 consecutive folds with shuffling. Each fold is then used once as a validation while the 4 remaining folds form the training set. The value of K is appropriate to avoid an overwhelmingly long running time as well as a non-repeatable evaluation.</p>
<h6>3. Model Analysis Result</h6>

<p><strong>1) Different Model Architecture</strong></p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_architecture.png" alt="diff_architecture" style="zoom:50%;" /></p>
<p align="center"><font size=2>Fig 6. CE Loss vs epoch, Classification Accuracy vs epoch (optimizer: SGD)</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_ar_box.png" alt="diff_ar_box" style="zoom:50%;" /></p>
<p align="center"><font size=2>Fig 7. Boxplot of test accuracy using k-fold (k-5) (optimizer: SGD)</font></p>

<p align="center"><font size=2>Table 6. Test accuracy using k-fold (k=5) (optimizer: SGD)</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/SGD_accuracy.png" alt="SGD_accuracy" style="zoom:50%;" /></p>
<p>We can see that the mean accuracy of model 2 is slightly higher but there is no apparent difference between two models’ performance in our case. However, we noticed that model 2 can train model in significantly shorter time period than model 1. Although two models have same amount of convolutional layers, model 2 has ‘fatter’ convolutional layer with more units, which speed up its training process. What’s more, the MaxPooling2D layer also reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation by down-sampling the input. Thus, model 2’s faster training speed can be well explained.</p>
<p><strong>2) Different Optimizer</strong></p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_opt.png" alt="diff_opt" style="zoom:50%;" /></p>
<p align="center"><font size=2>Fig 8. CNN model-2 CE Loss vs epoch, Classification Accuracy vs epoch using differnt optimizers</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_opt_box.png" alt="diff_opt_box" style="zoom:50%;" /></p>
<p align="center"><font size=2>Fig 9. Boxplot of CNN model-2 test accuracy using k-fold (k=5) with different optimizers</font></p>

<p align="center"><font size=2>Table 7. CNN model-2 Test accuracy using k-fold (k=5) with different optimizers</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/opt_accuracy.png" alt="opt_accuracy" style="zoom:50%;" /></p>
<p>We can see that there is no significant difference in accuracy using different optimizers in our case. SGD result is just slightly higher. But we do need to consider the choice of optimizers when building CNN. Taking Adam and SGD as an example, the latter one requires a relatively low memory requirements but the former one usually works better with little tuning of hyperparameters.</p>
<h4>2.3 SVM</h4>

<p>SVM intends to construct a hyperplane or set of hyperplanes that has the largest distance to the nearest training data point of any class to reduce the classifier’s generalization error. In other words, the main object of SVM is to maximize the geometric margin. </p>
<p>In this part, we just used the built-in model of SVM in <code>sklearn</code>. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># load dataset</span></span><br><span class="line">    x_train, y_train = util.load_dataset(training_mode=<span class="literal">True</span>)</span><br><span class="line">    m = x_train.shape[<span class="number">0</span>]</span><br><span class="line">    n = x_train.shape[<span class="number">1</span>]</span><br><span class="line">    x_train = x_train.reshape(m, n * n)</span><br><span class="line">    x_test, y_test = util.load_dataset(training_mode=<span class="literal">False</span>)</span><br><span class="line">    m = x_test.shape[<span class="number">0</span>]</span><br><span class="line">    n = x_test.shape[<span class="number">1</span>]</span><br><span class="line">    x_test = x_test.reshape(m, n * n)</span><br><span class="line"></span><br><span class="line">    x_train = x_train / <span class="number">255.0</span></span><br><span class="line">    x_test = x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># build SVM model</span></span><br><span class="line">    svm = SVC(C=<span class="number">5</span>, gamma=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    start_time = dt.datetime.now()</span><br><span class="line">    svm.fit(x_train, y_train)</span><br><span class="line">    end_time = dt.datetime.now()</span><br><span class="line">    elapsed_time = end_time - start_time</span><br><span class="line">    print(<span class="string">'Elapsed learning &#123;&#125;'</span>.format(str(elapsed_time)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># predict</span></span><br><span class="line">    expected = y_test</span><br><span class="line">    predicted = svm.predict(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># confusion matrix</span></span><br><span class="line">    cm = metrics.confusion_matrix(expected, predicted)</span><br><span class="line">    print(<span class="string">"Confusion matrix:\n%s"</span> % cm)</span><br><span class="line">    plot_confusion_matrix(cm)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get accuracy</span></span><br><span class="line">    print(<span class="string">"Training Accuracy=&#123;&#125;"</span>.format(metrics.accuracy_score(y_train, svm.predict(x_train))))</span><br><span class="line">    print(<span class="string">"Testing Accuracy=&#123;&#125;"</span>.format(metrics.accuracy_score(y_test, svm.predict(x_test))))</span><br></pre></td></tr></table></figure>
<p align="center"><font size=2>Table 8. Performance of SVM</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/svm_result.png" alt="svm_result" style="zoom:35%;" /></p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/conf_matrix_SVM.png" alt="conf_matrix_SVM" style="zoom:60%;" /></p>
<p align="center"><font size=2>Fig 10. Confusion matrix of SVM</font></p>

<p>Fig 10 shows the confusion matrix. We know that the diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions. For this SVM model, all of the diagonal values are beyond 850, which corresponds to the high accuracy of the model.</p>
<h4>2.4 Model Comparison</h4>

<p>According to the previous experiment with 6 different algorithms (9 models in total), we summarized the model performance in table 9.</p>
<p align="center"><font size=2>Table 9. Different models performance</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/diff_model.png" alt="diff_model" style="zoom:50%;" /></p>
<p>All of the models we built have a relatively high accuracy, among which, CNN model performs the best, and the Softmax regression without regularization performs the worst. If we take training time into consideration, simple-NN has the quickest training speed.</p>
<h3>III. Feature Visuallization</h3>

<h4>3.1 PCA</h4>

<p>Principal Components analysis (PCA), which tries to identify the subspace in which the data approximately lies, is extensionally used for dimensionality reduction for the visualization of high dimensional data. The main object of PCA is to provide a minimum number of variables that keeps the maximum amount of variation or information about how the original data is distributed using the correlation between some dimensions.  </p>
<p>From fig 11, the first two components account for about 25% of the variation in the entire dataset. If we do scatter plot to show the first two components as fig 12 shows, we can see that they do contain some information especially for digits like 0.0. However, it’s not enough to separate different classes apart clearly. Thus, next we will use another technique to see if it can provide us with better feature visualization results.</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/dim_PCA.png" alt="dim_PCA" style="zoom:80%;" /></p>
<p align="center"><font size=2>Fig 11. Dimensionality reduction using PCA</font></p>

<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/PCA.png" alt="PCA" style="zoom:90%;" /></p>
<p align="center"><font size=2>Fig 12. PCA using sklearn</font></p>

<h4>3.2 t-SNE</h4>

<p>t-SNE stands for t-Distributed Stochastic Neighbor Embedding, which is another method for dimensionality reduction. Its main goal is to minimize the divergence between two distributions, a distribution that measures pairwise similarities of the input objects and a distribution that measures pairwise similarities of the corresponding low-dimensional points in the embedding.</p>
<p>Due to the fact that the entire dataset needs very long time for t-SNE to process, we used a subset data of <em>10k</em> size. As fig 13 shows, the digits are clearly clustered in their own sub groups. It would be easier to assign new points to its label now.</p>
<p><img src="/Users/charlotte/hexofolder/source/_posts/MNIST-Image-Classification/t-SNE.png" alt="t-SNE" style="zoom:90%;" /></p>
<p align="center"><font size=2>Fig 13. t-SNE using sklearn</font></p>



<h3>IV. Conclusion</h3>

<p>In this project, we implemented MNIST digit image classification using six different algorithms including Logistic Regression (Softmax), Logistic Regression with Ridge loss, Logistic Regression with Lasso loss, simple-NN, CNN and SVM. We built 9 models in total with some parameter tuning and regularization. Among all the models, CNN performs the best with highest accuracy while Softmax regression without regularization performs the worst. In general, all these algorithms can fulfill our requirements for model accuracy. However, some of the models can take 2-3 hours to train each time. Thus, we do need to consider memory and time cost for training different models, from which aspect, the simple-NN is the best. In the third part, we also conducted feature visualization using PCA and t-SNE. For future work, we think that the optimal model doesn’t only require the stable and outstanding classification ability but also the capacity to avoid suffering from the accuracy-training cost tradeoff too much.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/04/Intro-of-ResNet-and-VGG/" rel="next" title="Intro of ResNet and VGG">
                <i class="fa fa-chevron-left"></i> Intro of ResNet and VGG
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/charlotte.png"
                alt="Yifan Cheng" />
            
              <p class="site-author-name" itemprop="name">Yifan Cheng</p>
              <p class="site-description motion-element" itemprop="description">Time waits for no one:)</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#"><span class="nav-number">2.</span> <span class="nav-text">I. Data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 Dataset Introduction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 Data Preprocessing</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#"><span class="nav-number">3.</span> <span class="nav-text">II. Image Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 Logistic Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#"><span class="nav-number">3.1.1.</span> <span class="nav-text">2.1.1 Multinomial Logistic Regression</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#"><span class="nav-number">3.1.2.</span> <span class="nav-text"> 2.1.2 Multinomial Logistic Regression with Ridge Loss</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#"><span class="nav-number">3.1.3.</span> <span class="nav-text">2.1.3 Multinomial Logistic Regression with Lasso Loss</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#"><span class="nav-number">3.1.4.</span> <span class="nav-text">2.1.4 Basic Conclusion for Logistic Regression</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 Neural Network</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#"><span class="nav-number">3.2.1.</span> <span class="nav-text">2.2.1 Simple-NN</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#"><span class="nav-number">3.2.2.</span> <span class="nav-text"> 2.2.2 CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">1. Build Model</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">2. Evaluate Model</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#"><span class="nav-number">3.2.2.3.</span> <span class="nav-text">3. Model Analysis Result</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 SVM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">3.4.</span> <span class="nav-text">2.4 Model Comparison</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#"><span class="nav-number">4.</span> <span class="nav-text">III. Feature Visuallization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 PCA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 t-SNE</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#"><span class="nav-number">5.</span> <span class="nav-text">IV. Conclusion</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yifan Cheng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
